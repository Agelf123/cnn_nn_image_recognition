{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with Neural Nets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a procedure for building a neural network to recognize handwritten digits.  The data is from Kaggle, and you will submit your results to Kaggle to test how well you did!\n",
    "\n",
    "1. Load the training data (`train.csv`) from Kaggle\n",
    "2. Setup X and y (feature matrix and target vector)\n",
    "3. Split X and y into train and test subsets.\n",
    "4. Preprocess your data\n",
    "\n",
    "   - When dealing with image data, you need to normalize your `X` by dividing each value by the max value of a pixel (255).\n",
    "   - Since this is a multiclass classification problem, keras needs `y` to be a one-hot encoded matrix\n",
    "   \n",
    "5. Create your network.\n",
    "\n",
    "   - Remember that for multi-class classification you need a softamx activation function on the output layer.\n",
    "   - You may want to consider using regularization or dropout to improve performance.\n",
    "   \n",
    "6. Trian your network.\n",
    "7. If you are unhappy with your model performance, try to tighten up your model by adding hidden layers, adding hidden layer units, chaning the activation functions on the hidden layers, etc.\n",
    "8. Load in Kaggle's `test.csv`\n",
    "9. Create your predictions (these should be numbers in the range 0-9).\n",
    "10. Save your predictions and submit them to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For this lab, you should complete the above sequence of steps for _at least_ two of the four \"configurations\":\n",
    "\n",
    "1. Using a `tensorflow` network\n",
    "2. Using a `keras` \"sequential\" network\n",
    "3. Using a `keras` convolutional network\n",
    "4. Using a `tensorflow` convolutional network (we did _not_ cover this in class!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/aryehgelfand/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[train.columns[1:]].values\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.\n",
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1993)\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.shape\n",
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[1], input_shape=X_train[0].shape, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(.005))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 10500 samples\n",
      "Epoch 1/10\n",
      "31500/31500 [==============================] - 14s 441us/step - loss: 1.5846 - accuracy: 0.9097 - val_loss: 0.4466 - val_accuracy: 0.9393\n",
      "Epoch 2/10\n",
      "31500/31500 [==============================] - 16s 510us/step - loss: 0.4327 - accuracy: 0.9353 - val_loss: 0.4725 - val_accuracy: 0.9329\n",
      "Epoch 3/10\n",
      "31500/31500 [==============================] - 11s 351us/step - loss: 0.4315 - accuracy: 0.9385 - val_loss: 0.4364 - val_accuracy: 0.9390\n",
      "Epoch 4/10\n",
      "31500/31500 [==============================] - 9s 293us/step - loss: 0.4219 - accuracy: 0.9415 - val_loss: 0.4106 - val_accuracy: 0.9448\n",
      "Epoch 5/10\n",
      "31500/31500 [==============================] - 9s 272us/step - loss: 0.4020 - accuracy: 0.9435 - val_loss: 0.4311 - val_accuracy: 0.9377\n",
      "Epoch 6/10\n",
      "31500/31500 [==============================] - 9s 274us/step - loss: 0.4037 - accuracy: 0.9462 - val_loss: 0.4327 - val_accuracy: 0.9437\n",
      "Epoch 7/10\n",
      "31500/31500 [==============================] - 9s 272us/step - loss: 0.3914 - accuracy: 0.9483 - val_loss: 0.4008 - val_accuracy: 0.9492\n",
      "Epoch 8/10\n",
      "31500/31500 [==============================] - 8s 270us/step - loss: 0.3652 - accuracy: 0.9506 - val_loss: 0.3810 - val_accuracy: 0.9489\n",
      "Epoch 9/10\n",
      "31500/31500 [==============================] - 9s 284us/step - loss: 0.3434 - accuracy: 0.9517 - val_loss: 0.3698 - val_accuracy: 0.9536\n",
      "Epoch 10/10\n",
      "31500/31500 [==============================] - 9s 285us/step - loss: 0.3335 - accuracy: 0.9539 - val_loss: 0.3780 - val_accuracy: 0.9479\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_sc, y_train, validation_data=(X_test_sc, y_test), epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.952254, 0.949999988079071)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy'][-1], history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test = test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Label'] = pred\n",
    "test['ImageId'] = range(1,test.shape[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['ImageId', 'Label']].to_csv('reg_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['label'])\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "\n",
    "# Scale each value to be between 0 and 1.\n",
    "X /= 255\n",
    "\n",
    "# Normalize\n",
    "X -= .5\n",
    "\n",
    "# Reshape each image to be 28 x 28 x 1 (since black/white)\n",
    "X = X.values.reshape(X.shape[0], 28, 28, 1)\n",
    "\n",
    "# Convert y into categorical variables\n",
    "y = np_utils.to_categorical(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1993, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31500, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential([\n",
    "    # Input layer\n",
    "    Conv2D(\n",
    "        filters     = 16, \n",
    "        kernel_size = 4, # start wide and take convolution slowly\n",
    "        activation  = 'relu', \n",
    "        input_shape = (28,28,1), #input layer\n",
    "        padding     = \"same\" # keeps original dimensions\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters     = 32, \n",
    "        kernel_size = 4, # start wide and take convolution slowly\n",
    "        activation  = 'relu', \n",
    "        padding     = \"same\" # keeps original dimensions\n",
    "    ),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "\n",
    "    Conv2D(filters = 32, kernel_size = 3, activation = \"relu\"),\n",
    "    Conv2D(filters = 64, kernel_size = 3, activation = \"relu\"),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.5),\n",
    "\n",
    "    Flatten(), # transition from convolution into standard neural network\n",
    "    \n",
    "    # Dense layer #1\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dense(16, activation = 'relu'),\n",
    "    \n",
    "    # Output layer\n",
    "    Dense(10, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(\n",
    "    loss      = 'categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics   = ['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 10500 samples\n",
      "Epoch 1/20\n",
      "31500/31500 [==============================] - 117s 4ms/step - loss: 0.7417 - accuracy: 0.7421 - val_loss: 0.1387 - val_accuracy: 0.9589\n",
      "Epoch 2/20\n",
      "31500/31500 [==============================] - 102s 3ms/step - loss: 0.1440 - accuracy: 0.9560 - val_loss: 0.0798 - val_accuracy: 0.9770\n",
      "Epoch 3/20\n",
      "31500/31500 [==============================] - 129s 4ms/step - loss: 0.0949 - accuracy: 0.9712 - val_loss: 0.0638 - val_accuracy: 0.9809\n",
      "Epoch 4/20\n",
      "31500/31500 [==============================] - 109s 3ms/step - loss: 0.0749 - accuracy: 0.9769 - val_loss: 0.0515 - val_accuracy: 0.9833\n",
      "Epoch 5/20\n",
      "31500/31500 [==============================] - 154s 5ms/step - loss: 0.0605 - accuracy: 0.9816 - val_loss: 0.0439 - val_accuracy: 0.9869\n",
      "Epoch 6/20\n",
      "31500/31500 [==============================] - 116s 4ms/step - loss: 0.0526 - accuracy: 0.9827 - val_loss: 0.0434 - val_accuracy: 0.9870\n",
      "Epoch 7/20\n",
      "31500/31500 [==============================] - 134s 4ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.0381 - val_accuracy: 0.9883\n",
      "Epoch 8/20\n",
      "31500/31500 [==============================] - 191s 6ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.0381 - val_accuracy: 0.9889\n",
      "Epoch 9/20\n",
      "31500/31500 [==============================] - 131s 4ms/step - loss: 0.0366 - accuracy: 0.9872 - val_loss: 0.0383 - val_accuracy: 0.9889\n",
      "Epoch 10/20\n",
      "31500/31500 [==============================] - 123s 4ms/step - loss: 0.0374 - accuracy: 0.9871 - val_loss: 0.0332 - val_accuracy: 0.9899\n",
      "Epoch 11/20\n",
      "31500/31500 [==============================] - 126s 4ms/step - loss: 0.0348 - accuracy: 0.9886 - val_loss: 0.0349 - val_accuracy: 0.9895\n",
      "Epoch 12/20\n",
      "31500/31500 [==============================] - 131s 4ms/step - loss: 0.0332 - accuracy: 0.9892 - val_loss: 0.0372 - val_accuracy: 0.9902\n",
      "Epoch 13/20\n",
      "31500/31500 [==============================] - 142s 5ms/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.0348 - val_accuracy: 0.9891\n",
      "Epoch 14/20\n",
      "31500/31500 [==============================] - 142s 5ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 0.0320 - val_accuracy: 0.9907\n",
      "Epoch 15/20\n",
      "31500/31500 [==============================] - 69s 2ms/step - loss: 0.0332 - accuracy: 0.9893 - val_loss: 0.0321 - val_accuracy: 0.9904\n",
      "Epoch 16/20\n",
      "31500/31500 [==============================] - 68s 2ms/step - loss: 0.0262 - accuracy: 0.9913 - val_loss: 0.0314 - val_accuracy: 0.9909\n",
      "Epoch 17/20\n",
      "31500/31500 [==============================] - 66s 2ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.0304 - val_accuracy: 0.9908\n",
      "Epoch 18/20\n",
      "31500/31500 [==============================] - 64s 2ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.0297 - val_accuracy: 0.9910\n",
      "Epoch 19/20\n",
      "31500/31500 [==============================] - 64s 2ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.0351 - val_accuracy: 0.9913\n",
      "Epoch 20/20\n",
      "31500/31500 [==============================] - 65s 2ms/step - loss: 0.0278 - accuracy: 0.9910 - val_loss: 0.0303 - val_accuracy: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x145271d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(X_train,\n",
    "                      y_train,\n",
    "                      batch_size=128,\n",
    "                      validation_data=(X_test, y_test),\n",
    "                      epochs=20,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "md = test.astype('float32')\n",
    "\n",
    "# Scale each value to be between 0 and 1.\n",
    "md /= 255\n",
    "\n",
    "# Normalize\n",
    "md -= .5\n",
    "\n",
    "# Reshape each image to be 28 x 28 x 1 (since black/white)\n",
    "md = md.values.reshape(md.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_3.predict_classes(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=range(1,test.shape[0]+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(1, 28001)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(1,test.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = pred\n",
    "df['ImageId'] = range(1,test.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ImageId', 'Label']].to_csv('cnn_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  ImageId\n",
       "1      2        1\n",
       "2      0        2\n",
       "3      9        3\n",
       "4      0        4\n",
       "5      3        5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
